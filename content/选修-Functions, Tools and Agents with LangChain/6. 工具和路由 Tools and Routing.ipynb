{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b815ef73",
   "metadata": {},
   "source": [
    "# 工具和路由 Tools and Routing\n",
    "\n",
    " - [一、设置OpenAI API Key](#一、设置OpenAI-API-Key)\n",
    " - [二、通过Langchain定义工具](#二、通过Langchain定义工具)\n",
    "     - [2.1 通过装饰器之间定义Tool](#2.1-通过装饰器之间定义Tool)\n",
    "     - [2.2 通过pydantic类定义Tool](#2.2-通过pydantic类定义Tool)\n",
    "     - [2.3 天气查询应用案例](#2.3-天气查询应用案例)\n",
    "     - [2.4 通过tool定义function](#2.4-通过tool定义function)\n",
    "     - [2.5 通过API定义function案例](#2.5-通过API定义function案例)\n",
    " - [三、 路由](#三、路由)\n",
    "     - [3.1 Tool转换为Function](#3.1-Tool转换为Function)\n",
    "     - [3.2 通过route进行tools的选择](#3.2-通过route进行tools的选择)\n",
    "     - [3.3 输出解析器](#3.3-输出解析器)\n",
    " - [四、总结](#四、总结)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00b7c548",
   "metadata": {},
   "source": [
    "# 一、设置OpenAI-API-Key\n",
    "\n",
    "详细内容见`设置OpenAI_API_KEY.ipynb`文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415ecb77-9dd2-42a9-9066-708f9cfb04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "loaded = load_dotenv(find_dotenv(), override=True)\n",
    "# 从环境变量中获取 OpenAI API Key 或者直接赋值\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# 如果您使用的是官方 API，就直接用 https://api.siliconflow.cn/v1 就行。\n",
    "BASE_URL = \"https://api.siliconflow.cn/v1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6466fd33",
   "metadata": {},
   "source": [
    "# 二、通过Langchain定义工具"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "032bdb49",
   "metadata": {},
   "source": [
    "## 2.1-通过装饰器之间定义Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744a1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# tool装饰器包装了search函数\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"在网络上查询天气\"\"\"\n",
    "    return \"42度\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b73d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "在网络上查询天气\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "# 搜索工具的函数名\n",
    "print(search.name)\n",
    "#搜索工具的功能描述（即函数注释）\n",
    "print(search.description)\n",
    "# 搜索工具需要传递的参数\n",
    "print(search.args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d2d5a5",
   "metadata": {},
   "source": [
    "## 2.2-通过pydantic类定义Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8765af16-17fc-4490-98ab-4e9dd59337cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 Pydantic 库中的 BaseModel 类和 Field 函数，它们用于定义数据模型和字段。\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    \"\"\"\n",
    "    定义了 SearchInput 类中的一个属性 query，它是一个字符串类型。通过 Field 函数，你为这个字段提供了一些配置\n",
    "    其中 description 参数用于描述这个字段的用途，即 \"Thing to search for\"（要搜索的内容）。\n",
    "    \"\"\"\n",
    "    query: str = Field(description=\"你需要搜索的东西\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b3f7d0-a856-4842-82da-6c00df53e9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搜索工具类需要传递的参数\n",
    "search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbea2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_schema参数传递SearchInput工具类\n",
    "@tool(args_schema=SearchInput)\n",
    "def search_zh(query: str) -> str:\n",
    "    \"\"\"在网上查找温度\"\"\"\n",
    "    return \"42度\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcbf965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1937e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42度'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"圣弗朗西斯科\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65467dd0",
   "metadata": {},
   "source": [
    "## 2.3-天气查询应用案例\n",
    "整体代码逻辑：\n",
    "1. 使用 Pydantic 定义了输入类OpenMeteoInput，以及输入的两个参数（经度和纬度）的输入格式\n",
    "2. 定义了一个函数 get_current_temperature，该函数使用 OpenMeteo API 获取给定坐标位置的当前温度。\n",
    "3. get_current_temperature函数通过发送 HTTP 请求获取 API 响应，然后从响应中提取并计算出当前时间对应的温度。\n",
    "4. get_current_temperature函数返回一个字符串，其中包含了当前温度的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93b85b2-1786-4f63-8e65-cd6a8b5c0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# 定义输入类（input schema）\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"要获取天气数据的位置的纬度\") \n",
    "    longitude: float = Field(..., description=\"要获取天气数据的位置的经度\") \n",
    "\n",
    "# 使用 @tool 装饰器并指定输入模型\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"\"获取给定坐标的温度\"\"\"\n",
    "    \n",
    "    # Open Meteo API 的URL\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # 请求参数\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # 发送 API 请求\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    # 检查响应状态码\n",
    "    if response.status_code == 200:\n",
    "        # 解析 JSON 响应\n",
    "        results = response.json()\n",
    "    else:\n",
    "        # 处理请求失败的情况\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    # 获取当前 UTC 时间\n",
    "    current_utc_time = datetime.datetime.now(datetime.UTC)\n",
    "    \n",
    "    # 将时间字符串转换为 datetime 对象\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str).replace(tzinfo=datetime.timezone.utc) for time_str in results['hourly']['time']]\n",
    "    \n",
    "    # 获取温度列表\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    # 找到最接近当前时间的索引\n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    \n",
    "    # 获取当前温度\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    # 返回当前温度的字符串形式\n",
    "    return f'当前的温度是 {current_temperature}°C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731ed353-a27d-42df-89a8-9767bafb23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_temperature\n",
      "\"获取给定坐标的温度\n",
      "{'latitude': {'description': '要获取天气数据的位置的纬度', 'title': 'Latitude', 'type': 'number'}, 'longitude': {'description': '要获取天气数据的位置的经度', 'title': 'Longitude', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "# 工具的名字\n",
    "print(get_current_temperature.name)\n",
    "# 工具的功能描述\n",
    "print(get_current_temperature.description)\n",
    "# 工具的输入参数\n",
    "print(get_current_temperature.args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38cefc99",
   "metadata": {},
   "source": [
    "## 2.4-通过tool定义function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36aacbec-9cdd-414a-b502-168cea350a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入openai的模板\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6277b6a8-f197-4057-a96a-5ebb61e18520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': '\"获取给定坐标的温度',\n",
       " 'parameters': {'properties': {'latitude': {'description': '要获取天气数据的位置的纬度',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': '要获取天气数据的位置的经度', 'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将定义好的工具直接传入模板，打印tool的名字、描述和输入参数格式\n",
    "convert_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e088eceb-424b-4da6-981f-63322c9ac56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当前的温度是 39.7°C'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用工具\n",
    "get_current_temperature.invoke({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eefc272-d205-4bad-ab00-282ccb3cc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# 定义维基百科搜索的tool\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"打开维基百科搜索并获得页面的摘要\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]: #取前三个页面标题\n",
    "        try:\n",
    "            #使用 wikipedia 模块的 page 函数，获取指定标题的维基百科页面对象。\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False) \n",
    "            # 获取页面摘要\n",
    "            summaries.append(f\"页面: {page_title}\\n摘要: {wiki_page.summary}\")\n",
    "        except (\n",
    "            wikipedia.exceptions.PageError,\n",
    "            wikipedia.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"维基百科没有搜索到合适的结果\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "289c5d0c-0e71-4d70-963f-9d9f58e53d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_wikipedia'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 工具的名字\n",
    "search_wikipedia.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69756d79-ec2f-4185-89af-d14de817fc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'打开维基百科搜索并获得页面的摘要'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 工具的描述\n",
    "search_wikipedia.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5b876cd-cc6c-484d-a3fa-d8810e22d564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': '打开维基百科搜索并获得页面的摘要',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将工具格式化为 OpenAI 函数\n",
    "convert_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dfb10e9-5d1e-474a-9c8f-7abdf7939a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'页面: LangChain\\n摘要: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n页面: Retrieval-augmented generation\\n摘要: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper from Meta.\\n\\n\\n\\n页面: Model Context Protocol\\n摘要: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) models like large language models (LLMs) integrate and share data with external tools, systems, and data sources. Technology writers have dubbed MCP “the USB-C of AI apps”, underscoring its goal of serving as a universal connector between language-model agents and external software. Designed to standardize context exchange between AI assistants and software environments, MCP provides a model-agnostic universal interface for reading files, executing functions, and handling contextual prompts. It was officially announced and open-sourced by Anthropic in November 2024, with subsequent adoption by major AI providers including OpenAI and Google DeepMind.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "search_wikipedia.invoke({\"query\": \"langchain\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71add465",
   "metadata": {},
   "source": [
    "## 2.5-通过API定义function案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54cbe57e-f64c-4392-bcdd-9621fe1e46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openapi_spec_to_openai_fn可以把json格式的API定义转换成openai的function call格式\n",
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain.chains.openai_tools.openapi import openapi_spec_to_openai_fn\n",
    "\n",
    "# OpenAPISpec是标准化的API格式定义\n",
    "from langchain.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe38e50-874c-49bd-8681-f95dcab0b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json格式的API定义\n",
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.1.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "653156d4-d6a4-499b-aab3-cf4f7b1f0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从text中导入API的详细定义\n",
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ba6100-3c88-4b05-af93-784b57bf7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成openai的fuction call格式\n",
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91199697-c662-438f-8c68-e6daa8aad07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'listPets',\n",
       "  'description': 'List all pets',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'params': {'type': 'object',\n",
       "     'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'schema_format': 'int32',\n",
       "       'description': 'How many items to return at one time (max 100)'}},\n",
       "     'required': []}}}},\n",
       " {'name': 'createPets',\n",
       "  'description': 'Create a pet',\n",
       "  'parameters': {'type': 'object', 'properties': {}}},\n",
       " {'name': 'showPetById',\n",
       "  'description': 'Info for a specific pet',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'path_params': {'type': 'object',\n",
       "     'properties': {'petId': {'type': 'string',\n",
       "       'description': 'The id of the pet to retrieve'}},\n",
       "     'required': ['petId']}}}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看fuction的定义\n",
    "pet_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae8b3c1b-7a30-4b1b-abfd-e56f90b1d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed100888-f3d4-4739-bba5-f839033850a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型温度系数并传入function\n",
    "model = ChatOpenAI(temperature=0, model_name=\"deepseek-ai/DeepSeek-V3\", max_tokens=4096,\n",
    "                        openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
    "                        seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
    "                        extra_body={\n",
    "                            \"enable_thinking\": False\n",
    "                        }\n",
    "                        )\n",
    "pet_openai_tools = [{\"type\": \"function\", \"function\": x} for x in pet_openai_functions]\n",
    "model = model.bind(tools=pet_openai_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27d7817c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763bd2aa9a9e26cadc34c598bd1ea', 'function': {'arguments': '{\"params\":{\"limit\":3}}', 'name': 'listPets'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 269, 'total_tokens': 277, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763bd23aec9eca496ca05864c7441', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1efbacc2-2874-42a7-ad18-99abb03ff774-0', tool_calls=[{'name': 'listPets', 'args': {'params': {'limit': 3}}, 'id': '019763bd2aa9a9e26cadc34c598bd1ea', 'type': 'tool_call'}], usage_metadata={'input_tokens': 269, 'output_tokens': 8, 'total_tokens': 277, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入query，查看模型调用的function以及返回信息\n",
    "model.invoke(\"这三只宠物的名字叫什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a373750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763bde509912c0143f3040232d1cc', 'function': {'arguments': '{\"path_params\":{\"petId\":\"42\"}}', 'name': 'showPetById'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 270, 'total_tokens': 281, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763bdd8af21210153ac67e1323bf6', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1599c3ff-eb5f-4baa-b2de-0ba9fd437de1-0', tool_calls=[{'name': 'showPetById', 'args': {'path_params': {'petId': '42'}}, 'id': '019763bde509912c0143f3040232d1cc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 270, 'output_tokens': 11, 'total_tokens': 281, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"告诉我id为42的宠物的消息\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "198b21dd-c9de-491d-9a0c-71ae56727689",
   "metadata": {},
   "source": [
    "# 3、 路由\n",
    "\n",
    "展示一个函数调用的例子，用于在两个候选函数之间做出决策。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99c30e7d",
   "metadata": {},
   "source": [
    "## 3.1-Tool转换为Function\n",
    "\n",
    "鉴于我们上面提到的工具，让我们将它们格式化为 OpenAI 函数，并展示相同的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8137758c-c5d3-47df-9062-5e31d43657e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将工具格式化为 OpenAI 函数\n",
    "functions = [\n",
    "    convert_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": x} for x in functions]\n",
    "\n",
    "model = model.bind(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99120542-36bc-4ed1-aa9e-e2294e282c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763c07bc9b62881b184fd27e348a8', 'function': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 202, 'total_tokens': 220, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763c073b16a942f51e4528fc8b891', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--66280092-fb55-4dea-bb53-e9c70ff8f138-0', tool_calls=[{'name': 'get_current_temperature', 'args': {'latitude': 37.7749, 'longitude': -122.4194}, 'id': '019763c07bc9b62881b184fd27e348a8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 202, 'output_tokens': 18, 'total_tokens': 220, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型调用\n",
    "model.invoke(\"圣佛朗西斯科现在的温度是多少？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a20047d9-4b34-4e6c-9407-570af1559bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763c09f9afffa19c833f910b25c30', 'function': {'arguments': '{\"query\":\"langchain\"}', 'name': 'search_wikipedia'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 197, 'total_tokens': 204, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763c096e763b61be53a675be45171', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7e8453dd-2ab0-49a1-8305-dd53964251cf-0', tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'langchain'}, 'id': '019763c09f9afffa19c833f910b25c30', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 7, 'total_tokens': 204, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型调用\n",
    "model.invoke(\"什么是langchain？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "831a0506-1d5c-4bc3-b67f-24e201a4fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用template构造prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是个乐于助人的助理\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 创建处理链，将 prompt和model连接起来\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9c32ccc-6691-4dd5-98dc-aabf02563ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763c11430594f4232189db22ff678', 'function': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 209, 'total_tokens': 227, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763c10b7ca3ad862c175b78ebccdf', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3f6bcb5b-a363-4c6e-9c7c-8e95fe6aa956-0', tool_calls=[{'name': 'get_current_temperature', 'args': {'latitude': 37.7749, 'longitude': -122.4194}, 'id': '019763c11430594f4232189db22ff678', 'type': 'tool_call'}], usage_metadata={'input_tokens': 209, 'output_tokens': 18, 'total_tokens': 227, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入query进行调用\n",
    "chain.invoke({\"input\": \"圣佛朗西斯科现在的温度是多少？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "921e808c-6618-4d2f-85df-1f3089497724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入输出解析的包\n",
    "from langchain.agents.output_parsers import ToolsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094baef1-4140-41f4-9111-ff9710826e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建处理链，将 prompt、model 和 ToolsAgentOutputParser 连接起来\n",
    "chain = prompt | model | ToolsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f105e8e8-d418-4d4a-95eb-52636d4e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"圣佛朗西斯科现在的温度是多少？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "409b26c0-a1e0-4225-ae2e-396c1f76bf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印返回的类型，可以判断是否产生function的调用\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cdde008-4b11-4ab2-a01c-6ae394a7dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看调用的tool\n",
    "result[0].tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66ffb308-3d77-4acb-b4b5-e2b0d38f3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看tool的输入，result.message_log可以查看调用结果\n",
    "result[0].tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07e661b1-6d0d-43b9-9de4-19c6cceff291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当前的温度是 11.6°C'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用的获取温度的工具\n",
    "get_current_temperature(result[0].tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "057e3072-a203-4a5e-b1f6-b250cd7bd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继续调用\n",
    "result = chain.invoke({\"input\": \"你好!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5be6bc0f-5b81-49fa-ac16-b8896847d87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentFinish"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印返回的类型，可以判断是否产生function的调用\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd128d20-f552-4cc5-a45e-f47b58c9982b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': '你好！有什么可以帮您的吗？'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看返回值\n",
    "result.return_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75da727",
   "metadata": {},
   "source": [
    "## 3.2-通过route进行tools的选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "134f422a-b72b-40df-9552-cf9f9fc2d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "route会根据result进行tools的选择：\n",
    "AgentFinish：表示已经完成，可以输出\n",
    "AgentActionMessageLog：表示未完成，需要继续进行route调用tools\n",
    "\"\"\"\n",
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result[0].tool].run(result[0].tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11b727ca-f571-4410-8087-95c73a37c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | ToolsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da06e7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！有什么可以帮您的吗？'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"你好！\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6385c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'圣弗朗西斯科（旧金山）的天气可能会因季节和时间而变化。为了获取准确的当前天气信息，我需要知道具体的经纬度坐标。如果你能提供这些信息，我可以帮你查询；或者，你也可以告诉我一个具体的地标或区域，我可以尝试找到相关的天气数据。'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"圣弗朗西斯科的天气现在怎么样？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c0de3e7-2367-4cef-b3dd-efa69b701061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'页面: LangChain\\n摘要: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n页面: Retrieval-augmented generation\\n摘要: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper from Meta.\\n\\n\\n\\n页面: Model Context Protocol\\n摘要: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) models like large language models (LLMs) integrate and share data with external tools, systems, and data sources. Technology writers have dubbed MCP “the USB-C of AI apps”, underscoring its goal of serving as a universal connector between language-model agents and external software. Designed to standardize context exchange between AI assistants and software environments, MCP provides a model-agnostic universal interface for reading files, executing functions, and handling contextual prompts. It was officially announced and open-sourced by Anthropic in November 2024, with subsequent adoption by major AI providers including OpenAI and Google DeepMind.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"什么是langchain?\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1d0ffc6",
   "metadata": {},
   "source": [
    "# 四、英文版提示\n",
    "\n",
    "我们总结一下完整的调用流程：\n",
    "\n",
    "构造Prompt --> 调用模型 --> 解析模型返回的结果 --> 进行路由选择对应的tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b82fa885",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74ae5b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "\"Search for weather online\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "# 搜索工具的函数名\n",
    "print(search.name)\n",
    "#搜索工具的功能描述（即函数注释）\n",
    "print(search.description)\n",
    "# 搜索工具需要传递的参数\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1ceebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a00da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0afe28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2bf3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# 定义输入类（input schema）\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\") #要获取天气数据的位置的纬度\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\") #要获取天气数据的位置的经度\n",
    "\n",
    "# 使用 @tool 装饰器并指定输入模型\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    # Open Meteo API 的URL\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # 请求参数\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # 发送 API 请求\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    # 检查响应状态码\n",
    "    if response.status_code == 200:\n",
    "        # 解析 JSON 响应\n",
    "        results = response.json()\n",
    "    else:\n",
    "        # 处理请求失败的情况\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    # 获取当前 UTC 时间\n",
    "    current_utc_time = datetime.datetime.now(datetime.UTC)\n",
    "    \n",
    "    # 将时间字符串转换为 datetime 对象\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str).replace(tzinfo=datetime.timezone.utc) for time_str in results['hourly']['time']]\n",
    "    # 获取温度列表\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    # 找到最接近当前时间的索引\n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    \n",
    "    # 获取当前温度\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    # 返回当前温度的字符串形式\n",
    "    return f'The current temperature is {current_temperature}°C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "130925b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_temperature\n",
      "\"Fetch current temperature for given coordinates.\n",
      "{'latitude': {'description': 'Latitude of the location to fetch weather data for', 'title': 'Latitude', 'type': 'number'}, 'longitude': {'description': 'Longitude of the location to fetch weather data for', 'title': 'Longitude', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "# 工具的名字\n",
    "print(get_current_temperature.name)\n",
    "# 工具的功能描述\n",
    "print(get_current_temperature.description)\n",
    "# 工具的输入参数\n",
    "print(get_current_temperature.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "122e1ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': '\"Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入openai的模板\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "convert_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4e68f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 39.7°C'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7477093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# 定义维基百科搜索的tool\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]: #取前三个页面标题\n",
    "        try:\n",
    "            #使用 wikipedia 模块的 page 函数，获取指定标题的维基百科页面对象。\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False) \n",
    "            # 获取页面摘要\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            wikipedia.exceptions.PageError,\n",
    "            wikipedia.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2dd47d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search and get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将工具格式化为 OpenAI 函数\n",
    "convert_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5edf4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "# 将工具格式化为 OpenAI 函数\n",
    "\n",
    "functions = [\n",
    "    convert_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"deepseek-ai/DeepSeek-V3\", max_tokens=4096,\n",
    "                        openai_api_key=API_KEY, openai_api_base=BASE_URL, max_retries=3,\n",
    "                        seed=42, presence_penalty=0.1, frequency_penalty=0.1,\n",
    "                        extra_body={\n",
    "                            \"enable_thinking\": False\n",
    "                        }\n",
    "                        )\n",
    "\n",
    "pet_openai_tools = [{\"type\": \"function\", \"function\": x} for x in functions]\n",
    "\n",
    "model = model.bind(tools=pet_openai_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf91812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用template构造prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 创建处理链，将 prompt和model连接起来\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fefc329-b270-4ebb-b884-430e4e541e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入输出解析的包\n",
    "from langchain.agents.output_parsers import ToolsAgentOutputParser\n",
    "\n",
    "chain = prompt | model | ToolsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8ea3f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='get_current_temperature', tool_input={'latitude': 37.7749, 'longitude': -122.4194}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763cd4af18352cf313474a6fabd16', 'function': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 214, 'total_tokens': 232, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763cd43d1008dc26c808016db4128', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a6208f75-6fd3-4bf2-8e8d-31879216d16b-0', tool_calls=[{'name': 'get_current_temperature', 'args': {'latitude': 37.7749, 'longitude': -122.4194}, 'id': '019763cd4af18352cf313474a6fabd16', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 18, 'total_tokens': 232, 'input_token_details': {}, 'output_token_details': {}})], tool_call_id='019763cd4af18352cf313474a6fabd16')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Well, hello there! What can I do for you today? Or are we just exchanging pleasantries? 😏'}, log='Well, hello there! What can I do for you today? Or are we just exchanging pleasantries? 😏')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用并查看结果\n",
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c93eb1b-044f-4c52-bcd4-dcd0e01f42e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': \"Ah, LangChain! The sassy assistant is here to enlighten you. \\n\\n**LangChain** is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to make it easier to build, customize, and deploy LLM-powered applications. Think of it as a Swiss Army knife for working with AI models like GPT-3, GPT-4, and others.\\n\\n### Key Features of LangChain:\\n1. **Chains**: Combine multiple steps or calls to LLMs into a single workflow (e.g., question-answering, summarization).\\n2. **Agents**: Let the LLM decide what actions to take (like using tools or APIs) to solve a task.\\n3. **Memory**: Add statefulness to your applications (e.g., chatbots that remember past interactions).\\n4. **Document Loaders & Indexes**: Easily work with external data sources (PDFs, websites, etc.).\\n5. **Customizability**: Fine-tune and extend the framework to fit your needs.\\n\\n### Why Use LangChain?\\n- **Saves Time**: No need to reinvent the wheel for common LLM tasks.\\n- **Scalability**: Build complex applications without getting lost in boilerplate code.\\n- **Integration**: Works seamlessly with popular tools like OpenAI, Hugging Face, and more.\\n\\n### Example Use Cases:\\n- Chatbots with memory.\\n- Automated content generation.\\n- Question-answering systems over documents.\\n- Custom AI workflows.\\n\\nSo, if you're diving into the world of LLMs and want to avoid the headache of managing all the moving parts, LangChain is your new best friend. Or at least a very helpful acquaintance. 😏\\n\\nNeed more details or examples? Just ask!\"}, log=\"Ah, LangChain! The sassy assistant is here to enlighten you. \\n\\n**LangChain** is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to make it easier to build, customize, and deploy LLM-powered applications. Think of it as a Swiss Army knife for working with AI models like GPT-3, GPT-4, and others.\\n\\n### Key Features of LangChain:\\n1. **Chains**: Combine multiple steps or calls to LLMs into a single workflow (e.g., question-answering, summarization).\\n2. **Agents**: Let the LLM decide what actions to take (like using tools or APIs) to solve a task.\\n3. **Memory**: Add statefulness to your applications (e.g., chatbots that remember past interactions).\\n4. **Document Loaders & Indexes**: Easily work with external data sources (PDFs, websites, etc.).\\n5. **Customizability**: Fine-tune and extend the framework to fit your needs.\\n\\n### Why Use LangChain?\\n- **Saves Time**: No need to reinvent the wheel for common LLM tasks.\\n- **Scalability**: Build complex applications without getting lost in boilerplate code.\\n- **Integration**: Works seamlessly with popular tools like OpenAI, Hugging Face, and more.\\n\\n### Example Use Cases:\\n- Chatbots with memory.\\n- Automated content generation.\\n- Question-answering systems over documents.\\n- Custom AI workflows.\\n\\nSo, if you're diving into the world of LLMs and want to avoid the headache of managing all the moving parts, LangChain is your new best friend. Or at least a very helpful acquaintance. 😏\\n\\nNeed more details or examples? Just ask!\")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"langchain?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2dcb4b2-0e0d-425b-bff8-db7cd33afa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='search_wikipedia', tool_input={'query': 'San Francisco coordinates'}, log=\"\\nInvoking: `search_wikipedia` with `{'query': 'San Francisco coordinates'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '019763cdeea66df09dc6ae375c7e42a6', 'function': {'arguments': '{\"query\":\"San Francisco coordinates\"}', 'name': 'search_wikipedia'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 218, 'total_tokens': 226, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-ai/DeepSeek-V3', 'system_fingerprint': '', 'id': '019763cde6fea46a566f99ff1fb9f304', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7ac52ea5-fd7d-4e52-a0a4-0fdc4baa0528-0', tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'San Francisco coordinates'}, 'id': '019763cdeea66df09dc6ae375c7e42a6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 8, 'total_tokens': 226, 'input_token_details': {}, 'output_token_details': {}})], tool_call_id='019763cdeea66df09dc6ae375c7e42a6')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "139c45e6-65a4-4fcb-a109-e5ba41a80835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入tool包\n",
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7760cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result[0].tool].run(result[0].tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89d8b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | ToolsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67be1657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, hello there! What can I do for you today? Or are you just here to bask in my sassy brilliance? 😏'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用并查看结果\n",
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8bcd38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is a framework designed to simplify the development of applications that leverage large language models (LLMs) like OpenAI's GPT. It provides tools and abstractions to help developers build, chain, and manage interactions with LLMs, making it easier to create complex workflows, integrate external data sources, and maintain stateful conversations.\\n\\n### Key Features of LangChain:\\n1. **Chaining**: Allows you to chain multiple LLM calls or other operations together to create more sophisticated applications.\\n2. **Memory**: Supports maintaining context or memory across interactions, which is useful for chatbots or multi-step workflows.\\n3. **Data Augmentation**: Enables integration with external data sources (like databases or APIs) to provide richer responses.\\n4. **Agents**: Provides a way to build agents that can dynamically decide which actions to take based on user input.\\n5. **Customization**: Offers flexibility to customize prompts, models, and workflows to suit specific needs.\\n\\n### Use Cases:\\n- **Chatbots**: Build conversational agents with memory and context.\\n- **Question Answering**: Create systems that answer questions by pulling from external knowledge bases.\\n- **Summarization**: Automatically summarize long documents or articles.\\n- **Code Generation**: Assist with writing or debugging code.\\n\\nIn short, LangChain is like a Swiss Army knife for working with LLMs, making it easier to build powerful, context-aware applications without reinventing the wheel. And yes, it’s as cool as it sounds—unless you’re into reinventing wheels, in which case, carry on!\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"What is langchain?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bcabd4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Mission District, San Francisco\\nSummary: The Mission District (Spanish: Distrito de la Misión), commonly known as the Mission (Spanish: La Misión), is a neighborhood in San Francisco, California. One of the oldest neighborhoods in San Francisco, the Mission District's name is derived from Mission San Francisco de Asís, built in 1776 by the Spanish. The Mission is historically one of the most notable centers of the city's Hispanic community.\\n\\nPage: Presidio of San Francisco\\nSummary: The Presidio of San Francisco (originally, El Presidio Real de San Francisco or The Royal Fortress of Saint Francis) is a park and former U.S. Army post on the northern tip of the San Francisco Peninsula in San Francisco, California, and is part of the Golden Gate National Recreation Area.\\nIt had been a fortified location since September 17, 1776, when New Spain established the presidio to gain a foothold in Alta California and the San Francisco Bay. It passed to Mexico in 1820, which in turn passed it to the United States in 1848. As part of a military reduction program under the Base Realignment and Closure (BRAC) process from 1988, Congress voted to end the Presidio's status as an active military installation of the U.S. Army. On October 1, 1994, it was transferred to the National Park Service, ending 219 years of military use and beginning its next phase of mixed commercial and public use.\\nIn 1996, the United States Congress created the Presidio Trust to oversee and manage the interior 80% of the park's lands, with the National Park Service managing the coastal 20%. In a first-of-its-kind structure, Congress mandated that the Presidio Trust make the Presidio financially self-sufficient by 2013. The Presidio achieved the goal in 2005, eight years ahead of the deadline.\\nThe Presidio is at the southern end of the Golden Gate Bridge, and is crossed by the bridge approach road.\\nThe park has many wooded areas, hills, and scenic vistas overlooking the Golden Gate itself, the  Bridge, San Francisco Bay, and the Pacific Ocean. It was recognized as a California Historical Landmark in 1933 and as a National Historic Landmark in 1962.\\n\\nPage: Castro District, San Francisco\\nSummary: The Castro District, commonly referred to as the Castro, is a neighborhood in Eureka Valley in San Francisco. The Castro was one of the first gay neighborhoods in the United States. Having transformed from a working-class neighborhood through the 1960s and 1970s into one that came to represent some of the highest geographical and communal concentrations of same-sex coupling, the Castro remains one of the most prominent symbols of lesbian, gay and bisexual activism and events in the world.\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用\n",
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36e3fd-2cc0-472f-a21f-b1ded02e43fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
